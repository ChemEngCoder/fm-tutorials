{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5887593e",
   "metadata": {},
   "source": [
    "# üß¨ Tutorial 1: Data Extraction & Cleaning\n",
    "## Working with ProteinGym DMS Data\n",
    "\n",
    "---\n",
    "\n",
    "**Learning Objectives:**\n",
    "- Download and extract datasets from ProteinGym\n",
    "- Clean and standardize tabular data with pandas\n",
    "- Handle missing values and duplicates\n",
    "- Normalize DMS scores for machine learning\n",
    "- Visualize dataset characteristics\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd33e55",
   "metadata": {},
   "source": [
    "## üì• Step 1: Data Download\n",
    "\n",
    "We'll download the ProteinGym DMS (Deep Mutational Scanning) substitution dataset. Each CSV file represents one DMS experiment.\n",
    "\n",
    "**Data Source:** [ProteinGym](https://proteingym.org/download) ‚Üí DMS Assays ‚Üí substitutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07ad3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect working directory and set base path for data files\n",
    "# This handles two common execution scenarios:\n",
    "# 1. Running from the notebook's directory (Tutorial_1_Data_Cleaning/)\n",
    "# 2. Running from /workspace with repo at /workspace/tutorials\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "import urllib.request\n",
    "import zipfile\n",
    "\n",
    "cwd = Path.cwd()\n",
    "target_dir = Path(\"ProteinGym_DMS_data\") / \"DMS_ProteinGym_substitutions\"\n",
    "\n",
    "# Define scenarios to check\n",
    "scenarios = [\n",
    "    {\n",
    "        \"name\": \"notebook directory\",\n",
    "        \"check\": lambda: cwd.name == \"Tutorial_1_Data_Cleaning\",\n",
    "        \"base\": Path(\"..\")\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"/workspace\",\n",
    "        \"check\": lambda: cwd == Path(\"/workspace\"),\n",
    "        \"base\": Path(\"/workspace/tutorials\")\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"current directory\",\n",
    "        \"check\": lambda: True,\n",
    "        \"base\": cwd\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"fallback (parent directory)\",\n",
    "        \"check\": lambda: True,\n",
    "        \"base\": Path(\"..\")\n",
    "    }\n",
    "]\n",
    "\n",
    "# Find the first scenario where data directory exists, or use fallback\n",
    "BASE_DIR = None\n",
    "for scenario in scenarios:\n",
    "    if BASE_DIR is not None:\n",
    "        break\n",
    "    if not scenario[\"check\"]():\n",
    "        continue\n",
    "    \n",
    "    base_dir = scenario[\"base\"]\n",
    "    data_dir = base_dir / target_dir\n",
    "    if data_dir.exists():\n",
    "        BASE_DIR = base_dir\n",
    "        scenario_name = scenario[\"name\"]\n",
    "        print(f\"‚úì Detected: Running from {scenario_name}\")\n",
    "        print(f\"  Current directory: {cwd}\")\n",
    "        print(f\"  Base directory: {BASE_DIR.resolve()}\")\n",
    "        break\n",
    "\n",
    "# If no scenario found data, use the fallback (last scenario)\n",
    "if BASE_DIR is None:\n",
    "    BASE_DIR = scenarios[-1][\"base\"]\n",
    "    print(f\"‚ö†Ô∏è  Warning: Unknown execution scenario, using fallback\")\n",
    "    print(f\"  Current directory: {cwd}\")\n",
    "    print(f\"  Base directory: {BASE_DIR.resolve()}\")\n",
    "\n",
    "print(f\"\\nüìÇ Using base directory: {BASE_DIR.resolve()}\")\n",
    "\n",
    "# Download and extract ProteinGym DMS substitution dataset if needed\n",
    "data_dir = BASE_DIR / \"ProteinGym_DMS_data\" / \"DMS_ProteinGym_substitutions\"\n",
    "zip_url = \"https://marks.hms.harvard.edu/proteingym/ProteinGym_v1.3/DMS_ProteinGym_substitutions.zip\"\n",
    "zip_file = BASE_DIR / \"ProteinGym_DMS_data\" / \"DMS_ProteinGym_substitutions.zip\"\n",
    "\n",
    "# Check if data already exists\n",
    "if data_dir.exists() and data_dir.is_dir():\n",
    "    csv_files = [f for f in data_dir.iterdir() if f.suffix == '.csv']\n",
    "    if csv_files:\n",
    "        print(f\"\\n‚úì Data already downloaded!\")\n",
    "        print(f\"  Found {len(csv_files)} CSV files in {data_dir}\")\n",
    "    else:\n",
    "        print(f\"\\n‚ö†Ô∏è  Directory exists but contains no CSV files. Downloading...\")\n",
    "        # Remove empty directory and download\n",
    "        if data_dir.exists():\n",
    "            data_dir.rmdir()\n",
    "        download_and_extract = True\n",
    "else:\n",
    "    print(f\"\\nüì• Dataset not found. Downloading and extracting...\")\n",
    "    download_and_extract = True\n",
    "\n",
    "# Download and extract if needed\n",
    "if 'download_and_extract' in locals():\n",
    "    # Create parent directory if it doesn't exist\n",
    "    BASE_DIR.mkdir(exist_ok=True)\n",
    "    (BASE_DIR / \"ProteinGym_DMS_data\").mkdir(exist_ok=True)\n",
    "    \n",
    "    # Download the zip file\n",
    "    print(f\"  Downloading from: {zip_url}\")\n",
    "    urllib.request.urlretrieve(zip_url, zip_file)\n",
    "    print(f\"  ‚úì Downloaded to: {zip_file}\")\n",
    "    \n",
    "    # Extract the zip file\n",
    "    print(f\"  Extracting archive...\")\n",
    "    with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
    "        zip_ref.extractall(BASE_DIR / \"ProteinGym_DMS_data\")\n",
    "    print(f\"  ‚úì Extracted successfully\")\n",
    "    \n",
    "    # Remove the zip file\n",
    "    zip_file.unlink()\n",
    "    print(f\"  ‚úì Removed archive file\")\n",
    "    \n",
    "    # Verify extraction\n",
    "    csv_files = list(data_dir.glob('*.csv'))\n",
    "    if csv_files:\n",
    "        print(f\"\\n‚úì Dataset ready!\")\n",
    "        print(f\"  Found {len(csv_files)} CSV files in {data_dir}\")\n",
    "    else:\n",
    "        print(f\"\\n‚ö†Ô∏è  Warning: Extraction complete but no CSV files found in {data_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0bbfbd2",
   "metadata": {},
   "source": [
    "## üìä Step 2: Load and Inspect Data\n",
    "\n",
    "Now we'll load all CSV files and combine them into a single DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafc98a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# Path to your DMS substitution data folder\n",
    "data_dir = BASE_DIR / \"ProteinGym_DMS_data\" / \"DMS_ProteinGym_substitutions\"\n",
    "\n",
    "# Load all CSVs into a list of dataframes\n",
    "print(\"Loading CSV files...\")\n",
    "dfs = []\n",
    "csv_files = list(data_dir.glob(\"*.csv\"))\n",
    "\n",
    "if not csv_files:\n",
    "    print(f\"‚ö† No CSV files found at path: {data_dir}\")\n",
    "    print(\"  Please make sure the data has been downloaded first (run Step 1 cell above).\")\n",
    "else:\n",
    "    for f in csv_files:\n",
    "        df = pd.read_csv(f)\n",
    "        df[\"source_file\"] = f.stem  # Get filename without extension\n",
    "        dfs.append(df)\n",
    "    \n",
    "    # Combine into a single dataframe\n",
    "    data = pd.concat(dfs, ignore_index=True)\n",
    "    \n",
    "    print(f\"‚úì Loaded {len(dfs)} files with {len(data):,} total rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d881b44",
   "metadata": {},
   "source": [
    "### üîç Quick Data Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537a90d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few rows\n",
    "print(\"First 5 rows of the dataset:\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7a4a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data types and missing values info\n",
    "print(\"Dataset information:\")\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494f7812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count unique mutants\n",
    "num_unique = data['mutant'].nunique()\n",
    "print(f\"Number of unique mutants: {num_unique:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd5560a",
   "metadata": {},
   "source": [
    "## üßπ Step 3: Data Cleaning\n",
    "\n",
    "### 3.1 Standardize Column Names\n",
    "\n",
    "Let's rename columns to have consistent, clear names throughout our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3812a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make column names consistent and easier to work with\n",
    "df = data.rename(columns={\n",
    "    'DMS_score': 'score',\n",
    "    'mutant': 'mutation',\n",
    "    'mutated_sequence': 'mut_seq',\n",
    "    'DMS_score_bin': 'score_bin',\n",
    "    'DMS_bin_score': 'score_bin_float'\n",
    "})\n",
    "\n",
    "print(\"‚úì Column names standardized\")\n",
    "print(f\"New columns: {list(df.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391be171",
   "metadata": {},
   "source": [
    "### 3.2 Parse Mutation Strings\n",
    "\n",
    "Extract wildtype amino acid, position, and mutant amino acid from mutation notation (e.g., \"A123C\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd75374",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_mut(m):\n",
    "    \"\"\"\n",
    "    Parse mutation string (e.g., 'A123C') into components.\n",
    "    Returns: (wildtype_aa, position, mutant_aa)\n",
    "    \"\"\"\n",
    "    match = re.match(r\"([A-Z])(\\d+)([A-Z])\", str(m))\n",
    "    if match:\n",
    "        wt, pos, mut = match.groups()\n",
    "        return pd.Series([wt, int(pos), mut])\n",
    "    return pd.Series([np.nan, np.nan, np.nan])\n",
    "\n",
    "# Apply parsing to all mutations; this may take a moment\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Use tqdm to add a progress bar to the apply function\n",
    "tqdm.pandas(desc=\"Parsing mutations\")\n",
    "df[['wt_aa', 'position', 'mut_aa']] = df['mutation'].progress_apply(parse_mut)\n",
    "\n",
    "print(\"‚úì Mutations parsed successfully\")\n",
    "print(f\"Example: {df[['mutation', 'wt_aa', 'position', 'mut_aa']].head(3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be655e58",
   "metadata": {},
   "source": [
    "### 3.3 Remove Invalid and Duplicate Entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6151e643",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store original size\n",
    "original_size = len(df)\n",
    "\n",
    "# Drop rows with missing values in critical columns\n",
    "df = df.dropna(subset=['score', 'mutation', 'wt_aa', 'mut_aa'])\n",
    "\n",
    "# Remove duplicate entries (same mutation in same source file)\n",
    "df = df.drop_duplicates(subset=['source_file', 'mutation'])\n",
    "\n",
    "print(f\"‚úì Removed {original_size - len(df):,} invalid/duplicate entries\")\n",
    "print(f\"‚úì Final dataset size: {len(df):,} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67643373",
   "metadata": {},
   "source": [
    "## üìè Step 4: Score Normalization\n",
    "\n",
    "DMS scores can vary widely across different experiments. We'll normalize scores per experiment to help machine learning models generalize better.\n",
    "\n",
    "**Why normalize?** Each experiment has its own scale. Standardizing to mean ‚âà 0 and std ‚âà 1 allows fair comparison across experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0021c98",
   "metadata": {},
   "source": [
    "### 4.1 Examine Score Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6673823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the raw score distribution\n",
    "print(\"Raw DMS Score Statistics:\")\n",
    "print(f\"  Maximum: {df['score'].max():.4f}\")\n",
    "print(f\"  Minimum: {df['score'].min():.4f}\")\n",
    "print(f\"  Mean:    {df['score'].mean():.4f}\")\n",
    "print(f\"  Std Dev: {df['score'].std():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7a4471",
   "metadata": {},
   "source": [
    "### 4.2 Apply Z-Score Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9354d4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize scores per experiment (z-score normalization)\n",
    "df['score_norm'] = df.groupby('source_file')['score'].transform(\n",
    "    lambda x: (x - x.mean()) / x.std()\n",
    ")\n",
    "\n",
    "print(\"‚úì Scores normalized per experiment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04abff7c",
   "metadata": {},
   "source": [
    "### 4.3 Verify Cleaned Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b3e1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick inspection of cleaned data\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(df.head())\n",
    "\n",
    "print(\"\\nExperiment sizes:\")\n",
    "df.groupby('source_file').size().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3695ff8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the full cleaned dataset\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71e8da8",
   "metadata": {},
   "source": [
    "### 4.4 Verify Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97ca265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check: verify normalization worked correctly\n",
    "# Each experiment should have mean ‚âà 0 and std ‚âà 1\n",
    "print(\"Normalized scores per experiment (first 10):\")\n",
    "normalization_check = df.groupby('source_file')['score_norm'].agg(['mean', 'std'])\n",
    "print(normalization_check.head(10))\n",
    "\n",
    "print(\"\\n‚úì Normalization successful!\" if (abs(normalization_check['mean'].mean()) < 0.01) else \"‚ö† Check normalization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a53935",
   "metadata": {},
   "source": [
    "### 4.5 Save Cleaned Dataset\n",
    "\n",
    "Let's save our cleaned and normalized data for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab99d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cleaned dataset to CSV\n",
    "output_dir = BASE_DIR / \"ProteinGym_DMS_data\"\n",
    "output_file = output_dir / \"cleaned_ProteinGym_DMS_substitutions.csv\"\n",
    "\n",
    "# Ensure output directory exists\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"‚úì Cleaned dataset saved to: {output_file}\")\n",
    "print(f\"  Total rows: {len(df):,}\")\n",
    "print(f\"  Total columns: {len(df.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17232da3",
   "metadata": {},
   "source": [
    "## üéØ Ready for Machine Learning!\n",
    "\n",
    "Your cleaned dataset is now ready to use with protein language models:\n",
    "\n",
    "**Options:**\n",
    "- Feed `mut_seq` (mutated sequences) directly to models like **ESM-2**, **ProteinBERT**, or **ProtT5**\n",
    "- Use `(wildtype_sequence, mutation)` pairs for models that support variant input\n",
    "- Use `score_norm` as regression targets\n",
    "- Use `score_bin` for classification tasks\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88ba85d",
   "metadata": {},
   "source": [
    "## üìä Step 5: Data Visualization\n",
    "\n",
    "Let's explore our cleaned dataset visually to understand its characteristics and identify potential issues."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bfc0a7d",
   "metadata": {},
   "source": [
    "### 5.1 Setup Visualization Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84acb461",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set style for prettier plots\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "\n",
    "# Quick sanity check\n",
    "print(\"Dataset Summary Statistics:\")\n",
    "print(df.describe())\n",
    "print(\"\\n\" + \"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a876c092",
   "metadata": {},
   "source": [
    "### 5.2 DMS Score Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833ed9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Raw DMS scores\n",
    "axes[0].hist(df['score'], bins=50, color='steelblue', alpha=0.7, edgecolor='black')\n",
    "axes[0].set_title(\"Distribution of Raw DMS Scores\", fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel(\"DMS Score\", fontsize=12)\n",
    "axes[0].set_ylabel(\"Frequency\", fontsize=12)\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Normalized DMS scores\n",
    "axes[1].hist(df['score_norm'], bins=50, color='seagreen', alpha=0.7, edgecolor='black')\n",
    "axes[1].set_title(\"Distribution of Normalized DMS Scores\", fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel(\"Normalized Score (z-score)\", fontsize=12)\n",
    "axes[1].set_ylabel(\"Frequency\", fontsize=12)\n",
    "axes[1].axvline(x=0, color='red', linestyle='--', linewidth=2, label='Mean = 0')\n",
    "axes[1].legend()\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úì Score distributions look good! Normalization has centered the data around 0.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e872a420",
   "metadata": {},
   "source": [
    "### 5.3 Mutation Type Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd903df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract mutation type (e.g., 'A123C' ‚Üí 'AC')\n",
    "df['mutation_type'] = df['mutation'].str.replace(r'[0-9]', '', regex=True)\n",
    "top_mutations = df['mutation_type'].value_counts().head(20)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "top_mutations.plot(kind='bar', color='coral', edgecolor='black')\n",
    "plt.title('Top 20 Most Common Mutation Types', fontsize=16, fontweight='bold')\n",
    "plt.xlabel(\"Mutation Type (WT‚ÜíMutant)\", fontsize=12)\n",
    "plt.ylabel(\"Count\", fontsize=12)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"‚úì Found {df['mutation_type'].nunique()} unique mutation types\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daae1c03",
   "metadata": {},
   "source": [
    "### 5.4 Sequence Length Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bb7bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate sequence lengths\n",
    "df['seq_length'] = df['mut_seq'].str.len()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.hist(df['seq_length'], bins=50, color='mediumpurple', alpha=0.7, edgecolor='black')\n",
    "plt.title(\"Distribution of Mutated Sequence Lengths\", fontsize=16, fontweight='bold')\n",
    "plt.xlabel(\"Sequence Length (amino acids)\", fontsize=12)\n",
    "plt.ylabel(\"Frequency\", fontsize=12)\n",
    "plt.axvline(df['seq_length'].median(), color='red', linestyle='--', linewidth=2, \n",
    "            label=f'Median: {df[\"seq_length\"].median():.0f}')\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Sequence length stats:\")\n",
    "print(f\"  Min: {df['seq_length'].min()}\")\n",
    "print(f\"  Max: {df['seq_length'].max()}\")\n",
    "print(f\"  Median: {df['seq_length'].median():.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ff167c",
   "metadata": {},
   "source": [
    "### 5.5 Wild-Type Amino Acid Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39acc02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count wild-type amino acids\n",
    "wt_counts = df['wt_aa'].value_counts().sort_index()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "wt_counts.plot(kind='bar', color='teal', edgecolor='black')\n",
    "plt.title('Wild-Type Amino Acid Distribution', fontsize=16, fontweight='bold')\n",
    "plt.xlabel(\"Amino Acid (Single Letter Code)\", fontsize=12)\n",
    "plt.ylabel(\"Count\", fontsize=12)\n",
    "plt.xticks(rotation=0)\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úì All 20 standard amino acids represented!\" if len(wt_counts) == 20 else f\"Found {len(wt_counts)} amino acids\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618ceafc",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéâ Tutorial Complete!\n",
    "\n",
    "**What we accomplished:**\n",
    "1. ‚úÖ Downloaded and loaded ProteinGym DMS data\n",
    "2. ‚úÖ Cleaned and standardized the dataset\n",
    "3. ‚úÖ Parsed mutation strings into components\n",
    "4. ‚úÖ Normalized DMS scores for ML readiness\n",
    "5. ‚úÖ Visualized key dataset characteristics\n",
    "\n",
    "**Next steps:**\n",
    "- Use this cleaned data with protein language models (ESM-2, ProteinBERT, ProtT5)\n",
    "- Build predictive models for mutation effects\n",
    "- Explore uncertainty quantification techniques\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
